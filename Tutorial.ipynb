{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Uncertainty Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical analysis is the study of algorithms that use numerical approximation for problems involving mathematical analysis (Trefethen, 1992). Numerical analysis primarily involves studying numerical uncertainty, validating a program’s results, and the optimisation of operations. \n",
    "\n",
    "We focus on numerical uncertainty in order to get insight on the detection and quantification of numerical errors and their origin. The two methods of investigating numerical uncertainty are static and dynamic analysis. Static analysis analyses a program without executing it, thus it depends greatly on the algorithmic analysis of the program. While effective, static analysis cannot be scaled up to large code bases, which limits its scope. Dynamic analysis analyses a program during or after execution and while efficient, it is not generally as thorough as static analysis and is dependent on the program being analysed and its input data. Nonetheless, it is scalable and can be applied efficiently on large code bases.\n",
    "\n",
    "Stochastic arithmetic, a form of dynamic analysis, analyses a program’s execution to measure numerical error by executing the program multiple times with random numerical perturbations.\n",
    "Numerical uncertainty is determined by quantifying the errors that can occur in floating point arithmetic, these errors typically being rounding and truncation errors. \n",
    "More specifically, one type of rounding error, absorption errors, are caused by mathematical operations between large and small numbers where the shifting of decimal points in the mantissa causes a loss of precision. In turn, another rounding error, catastrophic cancellation, is the loss of leading significant digits caused by subtracting two approximately equal operands.\n",
    "Two stochastic arithmetic methods that compute numerical uncertainty are DSA (Discrete Stochastic Arithmetic) (Vignes, 2004) and MCA (Monte Carlo Arithmetic) (Parker, 1997). Both techniques leverage randomness to model loss of accuracy inherent to floating point arithmetic due to its finite precision. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/numerical_analysis.png\" alt=\"Image description\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MCA** is a variant of stochastic arithmetic that leverages randomness in fundamental floating-point operations, introducing a probabilistic element. We use it over DSA due to its scalability to large code bases. It simulates computations for a given virtual precision using the following perturbation: \\\n",
    "\n",
    "$$ inexact(x)=x+2^{e_{x}-t}\\xi $$\n",
    "\n",
    "where \n",
    "$$\n",
    "e_{x} \\textnormal{ is the exponent in the floating point representation of } x \\\\\n",
    "        t \\textnormal{ is the virtual precision and } \\\\\n",
    "        \\xi \\textnormal{ is a random uniform variable of } (-\\frac{1}{2},\\frac{1}{2})\n",
    "$$\n",
    "\n",
    "\n",
    "MCA has three modes that allow perturbation to be introduced in the function input (Precision Bounding---PB), the function output (Random Rounding---RR) or both (full $mca\\_mode$).  Full $mca\\_mode$ combines RR and PB in the following equation: \n",
    "\n",
    "$$mca\\_mode(x \\circ y)=inexact_{RR}(inexact_{PB}(x) \\circ inexact_{PB}(y))$$\n",
    "\n",
    "Random Rounding tracks rounding errors, while Precision Bounding tracks catastrophic cancellations, and full $mca\\_mode$ is a combination of both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificarlo** (Denis et al., 2015) is a clang-based compiler that replaces floating point operations by a generic call to one of several configurable floating point models available.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/verificarlo.png\" alt=\"Image description\" />\n",
    "</p>\n",
    "\n",
    "Verificarlo requires recompilation of a program in order to instrument the floating point operations, which is not always feasible on large, complex code bases such as Tensorflow or PyTorch.\n",
    "This is especially difficult when the clang compiler used by Verificarlo is incompatible with the one used by the program or if the program calls upon many third-party tools which would also require recompilation. \n",
    "\\\n",
    "Nonetheless, MCA can be leveraged in programs through the use of the **Fuzzy ecosystem** (Kiar et al., 2020), a collection of Python software packages compiled with Verificarlo.\n",
    "Fuzzy enables the instrumentation of different libraries by Verificarlo in order to quantify the numerical uncertainty present in code using these libraries.\n",
    "The [Fuzzy ecosystem](https://github.com/verificarlo/fuzzy) with instrumented packages available such as the Python interpreter, the Numpy and SciPy packages and the libmath library.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/tool_differences.png\" alt=\"Image description\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verrou** (Févotte et al., 2016) is a tool which also uses Monte Carlo Arithmetic to monitor the accuracy of floating point operations without needing to instrument the source code or recompile it. \n",
    "The Verrou tool is located at [Github](https://github.com/edf-hpc/verrou) and its documentation [here](https://edf-hpc.github.io/verrou/vr-manual.html#vr-cr.start-instrumentation).\n",
    "\n",
    "Verrou is based upon Valgrind (Nethercote et al., 2007), a framework allowing for plug-in tools which use dynamic binary instrumentation (DBI), i.e. the process of modifying instructions of a binary program while it executes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comparison of the most popular implementations of MCA and DSA is shown in the table below:\n",
    "\n",
    "|                          | **Verificarlo** | **Verrou** | **CADNA** |\n",
    "|:-------------------------------:|:---------------:|:----------:|:---------:|\n",
    "| **Theoretical Approach**        |      MCA        |     MCA    |    DSA    |\n",
    "| **Practical Approach**          |    Compiler     |     DBI    | Manual Implementation |\n",
    "| **Languages**                   |  C, C++, Fortran| All        | C, C++, Fortran |\n",
    "| **Perturbation Type**           | RR, PB, full $mca\\_mode$| RR, PB, full $mca\\_mode$ | RR |\n",
    "| **Parallelization**             | Yes             | No         | Conditionally upon Synchronisation |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MENTION REPRODUCIBILITY CRISIS ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verrou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* L. N. Trefethen, “The definition of numerical analysis,” Cornell University, Tech. Rep., 1992.\n",
    "* J. Vignes, “Discrete stochastic arithmetic for validating results of numerical software,” Numerical Algorithms, vol. 37, pp. 377–390, 2004.\n",
    "* D. S. Parker, Monte Carlo Arithmetic: Exploiting Randomness in Floating-Point Arithmetic. University of California (Los Angeles). Computer Science Department, 1997.\n",
    "* C. Denis, P. D. O. Castro, and E. Petit, “Verificarlo: Checking Floating Point Accuracy through Monte Carlo Arithmetic,” in 2016 IEEE 23nd Symposium on Computer Arithmetic (ARITH). Los Alamitos, CA, USA: IEEE Computer Society, jul 2016, pp. 55–62. [Online]. Available: https://doi.ieeecomputersociety.org/10.1109/ARITH.2016.31\n",
    "* G. Kiar, P. de Oliveira Castro, P. Rioux, E. Petit, S. T. Brown, A. C. Evans, and T. Glatard, “Comparing Perturbation Models for Evaluating Stability of Neuroimaging Pipelines,” The International Journal of High Performance Computing Applications, vol. 34, no. 5, pp. 491–501, 2020.\n",
    "* F. Févotte and B. Lathuilière, “Verrou: Assessing Floating-Point Accuracy Without Recompiling,” 2016.\n",
    "* N. Nethercote and J. Seward, “Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation,” ACM Sigplan notices, vol. 42, no. 6, pp. 89–100, 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
